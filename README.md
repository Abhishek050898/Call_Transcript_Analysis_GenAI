# Call_Transcript_Analysis_GenAI

## ğŸ“Œ Overview
This repository contains a Jupyter Notebook (`Transcript_Analysis.ipynb`) designed for transcript analysis. The notebook processes textual transcripts to extract Member texts, perform sentiment analysis, and generate outcome ( Issue Resolved / Follow-Up Needed) based on the transcript.

## ğŸ” Key Features
âœ… **Extracts "Member" responses** from transcripts to analyze customer sentiment.  
âœ… **Uses `cardiffnlp/twitter-roberta-base-sentiment`** for **sentiment classification** (Positive, Neutral, Negative).  
âœ… **Applies `facebook/bart-large-mnli` (Zero-Shot)** to classify whether an issue is **Resolved** or requires **Follow-Up**. 
âœ… **Stores labeled data in FAISS** for fast retrieval & continuous learning (Future Enhancement with larger dataset).   
âœ… **Future-ready** with **fine-tuning & self-improving models** using FAISS-triggered retraining (Future Enhancement with larger dataset).

---

# ğŸ“‚ Project Structure

```
Transcript_Analysis/
â”‚â”€â”€ ğŸ“„ README.md                 # Project Documentation
â”‚â”€â”€ ğŸ“„ Transcript_Analysis.ipynb  # Jupyter Notebook (Full Code)
â”‚â”€â”€ ğŸ“„ requirements.txt           # Required dependencies
â”‚â”€â”€ ğŸ“ data/                      # Folder containing data files
â”‚   â”‚â”€â”€ ğŸ“ transcripts/           # Folder containing raw transcript text files
```
## ğŸ“ Usage
1. Open Jupyter Notebook:
   ```sh
   jupyter notebook
   ```
2. Navigate to `Transcript_Analysis.ipynb` and open it.
3. Run each cell in order to process the transcript and analyze the data.
4. Modify the data path (transcripts) as needed for your specific use case.

---

## ğŸ“Š **Models & Techniques Used**
### **1ï¸âƒ£ Sentiment Analysis**
- **Model Used:** `cardiffnlp/twitter-roberta-base-sentiment`
- **Why?** Trained on tweets, making it effective for short, customer-centric sentences.
- **Output:** Labels (`Positive`, `Neutral`, `Negative`) + Confidence Score

### **2ï¸âƒ£ Call Outcome Classification**
- **Model Used:** `facebook/bart-large-mnli` (Zero-Shot)
- **Why?** Eliminates the need for labeled training data.
- **Output:** Labels (`Issue Resolved`, `Follow-Up Needed`) + Confidence Score

### **3ï¸âƒ£ FAISS for Vector Storage & Continuous Learning (Future Enhancement)**
- **Why?** Speeds up classification by storing & retrieving similar cases instead of running deep inference on every request.
- **How?**  
  âœ… Stores **MiniLM embeddings** of past cases and new cases.  
  âœ… When a new case arrives, FAISS searches for **similar past cases** and retrieves a label.  
  âœ… Every **100 new cases**, the system **triggers fine-tuning** for model improvement.

---

## ğŸš€ Installation

To use this project, clone the repository and install the necessary dependencies:

```sh
# Clone the repository
git clone https://github.com/yourusername/Transcript_Analysis.git
cd Transcript_Analysis

# Create a virtual environment (optional but recommended)
python -m venv venv
source venv/bin/activate  # On Windows use `venv\Scripts\activate`

# Install dependencies
pip install -r requirements.txt
```

*Maintained by [Abhishek Kumar](https://github.com/Abhishek050898).*
